{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad664a1-60d9-484f-9117-c3058fd149f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_type = \"csv\"\n",
    "first_row_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "aws_keys_df = spark.read.format (file_type)\\\n",
    ".option(\"header\",first_row_header )\\\n",
    ".option(\"sep\", delimiter)\\\n",
    ".load(\"/FileStore/tables/aws_keys_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a698ee73-f609-4482-bfdd-d2b4d8565503",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import urllib\n",
    "\n",
    "ACCESS_KEY = 'key'\n",
    "SECRET_KEY = 'key'\n",
    "Encoded_Secret_key = urllib.parse.quote(SECRET_KEY, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b86858-8fdb-45cf-a260-65710a01b1fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = 'myiplbucket07'\n",
    "Mount_name = \"/mnt/myiplbucket07\"\n",
    "SourceUri = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, Encoded_Secret_key, AWS_S3_BUCKET)\n",
    "dbutils.fs.mount(SourceUri, Mount_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f13df3-e0fa-47e6-b40b-3fe66a344b2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls \"/mnt/myiplbucket07/Ipl_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b97124da-e3ae-4aa9-b8ec-88628dc906f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0beea66d-062a-468b-a9cc-46d045626d03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, BooleanType, DateType, DecimalType\n",
    "from pyspark.sql.functions import col, when, sum, avg, row_number \n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abc5ee59-3c95-4d9f-821a-82d39a3f5b03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "#create session\n",
    "spark = SparkSession.builder.appName(\"IPL Data Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3a20846-5d9e-4642-a18b-6ec42dd12ceb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ball_by_ball_df = spark.read.option(\"header\", \"true\").csv(\"dbfs:/mnt/myiplbucket07/Ipl_data/Ball_By_Ball.csv\")\n",
    "Match_df = spark.read.option(\"header\", \"true\").csv(\"dbfs:/mnt/myiplbucket07/Ipl_data/Match.csv\")\n",
    "Player_df = spark.read.option(\"header\", \"true\").csv(\"dbfs:/mnt/myiplbucket07/Ipl_data/Player.csv\")\n",
    "Player_match_df = spark.read.option(\"header\", \"true\").csv(\"dbfs:/mnt/myiplbucket07/Ipl_data/Player_match.csv\")\n",
    "Team_df = spark.read.option(\"header\", \"true\").csv(\"dbfs:/mnt/myiplbucket07/Ipl_data/Team.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "783725cf-22a0-4086-b374-097c026130a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(Ball_by_ball_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4340f00-d926-4b67-bc7b-f4a5e2944cd6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ball_by_ball_schema = StructType([\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"over_id\", IntegerType(), True),\n",
    "    StructField(\"ball_id\", IntegerType(), True),\n",
    "    StructField(\"innings_no\", IntegerType(), True),\n",
    "    StructField(\"team_batting\", StringType(), True),\n",
    "    StructField(\"team_bowling\", StringType(), True),\n",
    "    StructField(\"striker_batting_position\", IntegerType(), True),\n",
    "    StructField(\"extra_type\", StringType(), True),\n",
    "    StructField(\"runs_scored\", IntegerType(), True),\n",
    "    StructField(\"extra_runs\", IntegerType(), True),\n",
    "    StructField(\"wides\", IntegerType(), True),\n",
    "    StructField(\"legbyes\", IntegerType(), True),\n",
    "    StructField(\"byes\", IntegerType(), True),\n",
    "    StructField(\"noballs\", IntegerType(), True),\n",
    "    StructField(\"penalty\", IntegerType(), True),\n",
    "    StructField(\"bowler_extras\", IntegerType(), True),\n",
    "    StructField(\"out_type\", StringType(), True),\n",
    "    StructField(\"caught\", BooleanType(), True),\n",
    "    StructField(\"bowled\", BooleanType(), True),\n",
    "    StructField(\"run_out\", BooleanType(), True),\n",
    "    StructField(\"lbw\", BooleanType(), True),\n",
    "    StructField(\"retired_hurt\", BooleanType(), True),\n",
    "    StructField(\"stumped\", BooleanType(), True),\n",
    "    StructField(\"caught_and_bowled\", BooleanType(), True),\n",
    "    StructField(\"hit_wicket\", BooleanType(), True),\n",
    "    StructField(\"obstructingfeild\", BooleanType(), True),\n",
    "    StructField(\"bowler_wicket\", BooleanType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"season\", IntegerType(), True),\n",
    "    StructField(\"striker\", IntegerType(), True),\n",
    "    StructField(\"non_striker\", IntegerType(), True),\n",
    "    StructField(\"bowler\", IntegerType(), True),\n",
    "    StructField(\"player_out\", IntegerType(), True),\n",
    "    StructField(\"fielders\", IntegerType(), True),\n",
    "    StructField(\"striker_match_sk\", IntegerType(), True),\n",
    "    StructField(\"strikersk\", IntegerType(), True),\n",
    "    StructField(\"nonstriker_match_sk\", IntegerType(), True),\n",
    "    StructField(\"nonstriker_sk\", IntegerType(), True),\n",
    "    StructField(\"fielder_match_sk\", IntegerType(), True),\n",
    "    StructField(\"fielder_sk\", IntegerType(), True),\n",
    "    StructField(\"bowler_match_sk\", IntegerType(), True),\n",
    "    StructField(\"bowler_sk\", IntegerType(), True),\n",
    "    StructField(\"playerout_match_sk\", IntegerType(), True),\n",
    "    StructField(\"battingteam_sk\", IntegerType(), True),\n",
    "    StructField(\"bowlingteam_sk\", IntegerType(), True),\n",
    "    StructField(\"keeper_catch\", BooleanType(), True),\n",
    "    StructField(\"player_out_sk\", IntegerType(), True),\n",
    "    StructField(\"matchdatesk\", DateType(), True)\n",
    "])\n",
    "\n",
    "Ball_by_ball_df = spark.read.schema(Ball_by_ball_schema).format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/mnt/myiplbucket07/Ipl_data/Ball_By_Ball.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf053053-d3e9-4f0b-bcd5-6bb98ccd740b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Match_Schema = StructType([\n",
    "    StructField(\"match_sk\", IntegerType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"team1\", StringType(), True),\n",
    "    StructField(\"team2\", StringType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"season_year\", IntegerType(), True),  # Assuming 'year' is represented as an integer\n",
    "    StructField(\"venue_name\", StringType(), True),\n",
    "    StructField(\"city_name\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True),\n",
    "    StructField(\"toss_winner\", StringType(), True),\n",
    "    StructField(\"match_winner\", StringType(), True),\n",
    "    StructField(\"toss_name\", StringType(), True),\n",
    "    StructField(\"win_type\", StringType(), True),\n",
    "    StructField(\"outcome_type\", StringType(), True),\n",
    "    StructField(\"manofmach\", StringType(), True),\n",
    "    StructField(\"win_margin\", IntegerType(), True),\n",
    "    StructField(\"country_id\", IntegerType(), True)\n",
    "])\n",
    "Match_df = spark.read.schema(Match_Schema).format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/mnt/myiplbucket07/Ipl_data/Match.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3232413-c78d-42d1-898b-6ccf6aa75266",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Player_schema = StructType([\n",
    "    StructField(\"player_sk\", IntegerType(), True),\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"batting_hand\", StringType(), True),\n",
    "    StructField(\"bowling_skill\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "Player_df = spark.read.schema(Player_schema).format(\"csv\").option(\"header\",\"true\").load(\"dbfs:/mnt/myiplbucket07/Ipl_data/Player.csv\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f93a53d-e53c-45f3-9cac-d703c91e0bbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Player_match_schema = StructType([\n",
    "    StructField(\"player_match_sk\", IntegerType(), True),\n",
    "    StructField(\"playermatch_key\", DecimalType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"batting_hand\", StringType(), True),\n",
    "    StructField(\"bowling_skill\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True),\n",
    "    StructField(\"role_desc\", StringType(), True),\n",
    "    StructField(\"player_team\", StringType(), True),\n",
    "    StructField(\"opposit_team\", StringType(), True),\n",
    "    StructField(\"season_year\", IntegerType(), True),\n",
    "    StructField(\"is_manofthematch\", BooleanType(), True),\n",
    "    StructField(\"age_as_on_match\", IntegerType(), True),\n",
    "    StructField(\"isplayers_team_won\", BooleanType(), True),\n",
    "    StructField(\"batting_status\", StringType(), True),\n",
    "    StructField(\"bowling_status\", StringType(), True),\n",
    "    StructField(\"player_captain\", StringType(), True),\n",
    "    StructField(\"opposit_captain\", StringType(), True),\n",
    "    StructField(\"player_keeper\", StringType(), True),\n",
    "    StructField(\"opposit_keeper\", StringType(), True)\n",
    "])\n",
    "\n",
    "Player_match_df = spark.read.schema(Player_match_schema).format(\"csv\").option(\"header\",\"true\").load(\"dbfs:/mnt/myiplbucket07/Ipl_data/Player_match.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7cb77d-ba5e-4c27-9b86-83bdae6eba3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Team_schema = StructType([\n",
    "    StructField(\"team_sk\", IntegerType(), True),\n",
    "    StructField(\"team_id\", IntegerType(), True),\n",
    "    StructField(\"team_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "Team_df = spark.read.schema(Team_schema).format(\"csv\").option(\"header\",\"true\").load(\"dbfs:/mnt/myiplbucket07/Ipl_data/Team.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f7b086e-4f7a-4a82-8370-e1c6470fcb38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter to include only valid deliveries (excluding extras like wides and no balls for specific analyses)\n",
    "Ball_by_ball_df = Ball_by_ball_df.filter((col(\"wides\") == 0) & (col(\"noballs\")==0))\n",
    "\n",
    "# Aggregation: Calculate the total and average runs scored in each match and inning\n",
    "total_and_avg_runs = Ball_by_ball_df.groupBy(\"match_id\", \"innings_no\").agg(\n",
    "    sum(\"runs_scored\").alias(\"total_runs\"),\n",
    "    avg(\"runs_scored\").alias(\"average_runs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c38a49-1f5c-4009-a182-6cdc5cb0bdc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Window Function: Calculate running total of runs in each match for each over\n",
    "windowSpec = Window.partitionBy(\"match_id\",\"innings_no\").orderBy(\"over_id\")\n",
    "\n",
    "Ball_by_ball_df = Ball_by_ball_df.withColumn(\n",
    "    \"running_total_runs\",\n",
    "    sum(\"runs_scored\").over(windowSpec)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10a9b8b4-8e63-44b8-9345-0fdb1afc3862",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Conditional Column: Flag for high impact balls (either a wicket or more than 6 runs including extras)\n",
    "Ball_by_ball_df = Ball_by_ball_df.withColumn(\n",
    "    \"high_impact\",\n",
    "    when((col(\"runs_scored\") + col(\"extra_runs\") > 6) | (col(\"bowler_wicket\") == True), True).otherwise(False)\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4586f3ee-b826-469e-8b01-adf772d8412f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ball_by_ball_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9fa3bfa-6082-4fa0-9e08-e9dc58151002",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, when\n",
    "\n",
    "# Extracting year, month, and day from the match date for more detailed time-based analysis\n",
    "Match_df = Match_df.withColumn(\"year\", year(\"match_date\"))\n",
    "Match_df = Match_df.withColumn(\"month\", month(\"match_date\"))\n",
    "match_df = Match_df.withColumn(\"day\", dayofmonth(\"match_date\"))\n",
    "\n",
    "# High margin win: categorizing win margins into 'high', 'medium', and 'low'\n",
    "Match_df = Match_df.withColumn(\n",
    "    \"win_margin_category\",\n",
    "    when(col(\"win_margin\") >= 100, \"High\")\n",
    "    .when((col(\"win_margin\") >= 50) & (col(\"win_margin\") < 100), \"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "# Analyze the impact of the toss: who wins the toss and the match\n",
    "Match_df = Match_df.withColumn(\n",
    "    \"toss_match_winner\",\n",
    "    when(col(\"toss_winner\") == col(\"match_winner\"), \"Yes\").otherwise(\"No\")\n",
    ")\n",
    "\n",
    "# Show the enhanced match DataFrame\n",
    "Match_df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953ec7fa-8a06-424a-96de-80bfed5d3239",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, regexp_replace\n",
    "\n",
    "# Normalize and clean player names\n",
    "Player_df = Player_df.withColumn(\"player_name\", lower(regexp_replace(\"player_name\", \"[^a-zA-Z0-9 ]\", \"\")))\n",
    "\n",
    "# Handle missing values in 'batting_hand' and 'bowling_skill' with a default 'unknown'\n",
    "Player_df = Player_df.na.fill({\"batting_hand\": \"unknown\", \"bowling_skill\": \"unknown\"})\n",
    "\n",
    "# Categorizing players based on batting hand\n",
    "Player_df = Player_df.withColumn(\n",
    "    \"batting_style\",\n",
    "    when(col(\"batting_hand\").contains(\"left\"), \"Left-Handed\").otherwise(\"Right-Handed\")\n",
    ")\n",
    "\n",
    "# Show the modified player DataFrame\n",
    "Player_df.show(2)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7209f897-ee7d-42f2-8ddc-1ae881a5303c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, current_date, expr\n",
    "\n",
    "# Add a 'veteran_status' column based on player age\n",
    "Player_match_df = Player_match_df.withColumn(\n",
    "    \"veteran_status\",\n",
    "    when(col(\"age_as_on_match\") >= 35, \"Veteran\").otherwise(\"Non-Veteran\")\n",
    ")\n",
    "\n",
    "# Dynamic column to calculate years since debut\n",
    "Player_match_df = Player_match_df.withColumn(\n",
    "    \"years_since_debut\",\n",
    "    (year(current_date()) - col(\"season_year\"))\n",
    ")\n",
    "\n",
    "# Show the enriched DataFrame\n",
    "Player_match_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7723c4c3-a2dc-46aa-8d51-5ce5175e7c34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Ball_by_ball_df.createOrReplaceTempView(\"Ball_by_ball\")\n",
    "Match_df.createOrReplaceTempView(\"Match\")\n",
    "Player_df.createOrReplaceTempView(\"Player\")\n",
    "Player_match_df.createOrReplaceTempView(\"Player_match\")\n",
    "Team_df.createOrReplaceTempView(\"Team\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15a350d7-3a9e-4650-876b-77925c2b65ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ball_by_ball_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5309ac85-3465-40d7-8b78-6c449d36f5ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_scoring_batsmen_per_season = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    p.player_name,\n",
    "    m.season_year,\n",
    "    SUM(b.runs_scored) AS total_runs \n",
    "    FROM ball_by_ball b\n",
    "    JOIN match m ON b.match_id = m.match_id   \n",
    "    JOIN player_match pm ON m.match_id = pm.match_id AND b.striker = pm.player_id     \n",
    "    JOIN player p ON p.player_id = pm.player_id\n",
    "    GROUP BY p.player_name, m.season_year\n",
    "    ORDER BY m.season_year, total_runs DESC\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03bb1705-7c47-4c6e-baf8-b24e1c83b5b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "top_scoring_batsmen_per_season.show(30)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa893a6-33b2-457d-aef9-aa2c832a85d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "economical_bowlers_powerplay = spark.sql(\"\"\"\n",
    "SELECT \n",
    "p.player_name, \n",
    "AVG(b.runs_scored) AS avg_runs_per_ball, \n",
    "COUNT(b.bowler_wicket) AS total_wickets\n",
    "FROM ball_by_ball b\n",
    "JOIN player_match pm ON b.match_id = pm.match_id AND b.bowler = pm.player_id\n",
    "JOIN player p ON pm.player_id = p.player_id\n",
    "WHERE b.over_id <= 6\n",
    "GROUP BY p.player_name\n",
    "HAVING COUNT(*) >= 1\n",
    "ORDER BY avg_runs_per_ball, total_wickets DESC\n",
    "\"\"\")\n",
    "economical_bowlers_powerplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543e89d3-db20-482e-aedf-9b709aaee297",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "toss_impact_individual_matches = spark.sql(\"\"\"\n",
    "SELECT m.match_id, m.toss_winner, m.toss_name, m.match_winner,\n",
    "       CASE WHEN m.toss_winner = m.match_winner THEN 'Won' ELSE 'Lost' END AS match_outcome\n",
    "FROM match m\n",
    "WHERE m.toss_name IS NOT NULL\n",
    "ORDER BY m.match_id\n",
    "\"\"\")\n",
    "toss_impact_individual_matches.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36ee1376-c522-4071-8831-56b418fd7997",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "average_runs_in_wins = spark.sql(\"\"\"\n",
    "SELECT p.player_name, AVG(b.runs_scored) AS avg_runs_in_wins, COUNT(*) AS innings_played\n",
    "FROM ball_by_ball b\n",
    "JOIN player_match pm ON b.match_id = pm.match_id AND b.striker = pm.player_id\n",
    "JOIN player p ON pm.player_id = p.player_id\n",
    "JOIN match m ON pm.match_id = m.match_id\n",
    "WHERE m.match_winner = pm.player_team\n",
    "GROUP BY p.player_name\n",
    "ORDER BY avg_runs_in_wins ASC\n",
    "\"\"\")\n",
    "average_runs_in_wins.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10b8f93-ed24-436c-9d47-d28ea381c153",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming 'economical_bowlers_powerplay' is already executed and available as a Spark DataFrame\n",
    "economical_bowlers_pd = economical_bowlers_powerplay.toPandas()\n",
    "\n",
    "# Visualizing using Matplotlib\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Limiting to top 10 for clarity in the plot\n",
    "top_economical_bowlers = economical_bowlers_pd.nsmallest(10, 'avg_runs_per_ball')\n",
    "plt.bar(top_economical_bowlers['player_name'], top_economical_bowlers['avg_runs_per_ball'], color='skyblue')\n",
    "plt.xlabel('Bowler Name')\n",
    "plt.ylabel('Average Runs per Ball')\n",
    "plt.title('Most Economical Bowlers in Powerplay Overs (Top 10)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eec53150-567f-49a7-b1de-2bbfe6d8d045",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "toss_impact_pd = toss_impact_individual_matches.toPandas()\n",
    "\n",
    "# Creating a countplot to show win/loss after winning toss\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='toss_winner', hue='match_outcome', data=toss_impact_pd)\n",
    "plt.title('Impact of Winning Toss on Match Outcomes')\n",
    "plt.xlabel('Toss Winner')\n",
    "plt.ylabel('Number of Matches')\n",
    "plt.legend(title='Match Outcome')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0efa121b-1a63-44f0-b022-cf801fdb6091",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "average_runs_pd = average_runs_in_wins.toPandas()\n",
    "\n",
    "# Using seaborn to plot average runs in winning matches\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_scorers = average_runs_pd.nlargest(10, 'avg_runs_in_wins')\n",
    "sns.barplot(x='player_name', y='avg_runs_in_wins', data=top_scorers)\n",
    "plt.title('Average Runs Scored by Batsmen in Winning Matches (Top 10 Scorers)')\n",
    "plt.xlabel('Player Name')\n",
    "plt.ylabel('Average Runs in Wins')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8063286-33da-4c87-aa5e-03cce0410cb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Execute SQL Query\n",
    "scores_by_venue = spark.sql(\"\"\"\n",
    "SELECT venue_name, AVG(total_runs) AS average_score, MAX(total_runs) AS highest_score\n",
    "FROM (\n",
    "    SELECT ball_by_ball.match_id, match.venue_name, SUM(runs_scored) AS total_runs\n",
    "    FROM ball_by_ball\n",
    "    JOIN match ON ball_by_ball.match_id = match.match_id\n",
    "    GROUP BY ball_by_ball.match_id, match.venue_name\n",
    ")\n",
    "GROUP BY venue_name\n",
    "ORDER BY average_score DESC\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f95a27e-2255-45fd-8823-a618a4a8d66c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert to Pandas DataFrame\n",
    "scores_by_venue_pd = scores_by_venue.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='average_score', y='venue_name', data=scores_by_venue_pd)\n",
    "plt.title('Distribution of Scores by Venue')\n",
    "plt.xlabel('Average Score')\n",
    "plt.ylabel('Venue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6220fa5-752f-4e5b-b8cc-b25e03cae4c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Execute SQL Query\n",
    "dismissal_types = spark.sql(\"\"\"\n",
    "SELECT out_type, COUNT(*) AS frequency\n",
    "FROM ball_by_ball\n",
    "WHERE out_type IS NOT NULL\n",
    "GROUP BY out_type\n",
    "ORDER BY frequency DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575f8092-1910-4869-a6ea-3540269d83a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "dismissal_types_pd = dismissal_types.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='frequency', y='out_type', data=dismissal_types_pd, palette='pastel')\n",
    "plt.title('Most Frequent Dismissal Types')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Dismissal Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "656640b2-3ec0-4b12-8707-00a9121b2c45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute SQL Query\n",
    "team_toss_win_performance = spark.sql(\"\"\"\n",
    "SELECT team1, COUNT(*) AS matches_played, SUM(CASE WHEN toss_winner = match_winner THEN 1 ELSE 0 END) AS wins_after_toss\n",
    "FROM match\n",
    "WHERE toss_winner = team1\n",
    "GROUP BY team1\n",
    "ORDER BY wins_after_toss DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4db9585-5ccb-4ec7-83f0-d5ce6cebb557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute SQL Query\n",
    "team_toss_win_performance = spark.sql(\"\"\"\n",
    "SELECT team1, COUNT(*) AS matches_played, SUM(CASE WHEN toss_winner = match_winner THEN 1 ELSE 0 END) AS wins_after_toss\n",
    "FROM match\n",
    "WHERE toss_winner = team1\n",
    "GROUP BY team1\n",
    "ORDER BY wins_after_toss DESC\n",
    "\"\"\")\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "team_toss_win_pd = team_toss_win_performance.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='wins_after_toss', y='team1', data=team_toss_win_pd)\n",
    "plt.title('Team Performance After Winning Toss')\n",
    "plt.xlabel('Wins After Winning Toss')\n",
    "plt.ylabel('Team')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e0d813f-ac6f-44c9-94d7-3c3df719614c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3114635766834259,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ipl_data_analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
